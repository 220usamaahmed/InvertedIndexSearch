# Search Engine Project - DSA
A search engine based on the paper [*The Anatomy of a Large-Scale Hypertextual Web Search Engine*](http://infolab.stanford.edu/~backrub/google.html) by Sergey Brin and Lawrence Page

## Using this Repository

#### Dependencies
Type the following command in Terminal to download required packages
	
	pip install -r requirements.txt

Then you need to download the following for NLTK:
	
1. Stopwords Corpus
2. Punkt Tokenizer Model

Type this in the python shell to get these

```python
import nltk
nltk.download()
```
#### Demo
To demo indexing go to the run.py file. This is the file
from which all other modules are called. There are 3 commented lines of code here.
Uncomment each line one at a time and run. Each operation also prints some data to
show what has been generated.
If the index is already generated, it will be overwritten. To prevent this from
happening every time we add a new documents, you have to create a new batch in
the dataset folder and specify in the generator modules to just look at those. Then
the indexing will only be done for those new documents.

## Working
__1. Generating Lexicon:__
The lexicon is generated. The lexicon is stored in a dictionary so there is no
need to sort it as search is done in constant time.

__2. Generating Forward Index:__
The next line generates the forward index using multiple threads. We made a
slightly different design decision here compared to the original Google paper.
Rather than creating buckets based on wordIDs and having duplications we
created buckets based on docIDs which eliminates duplicates. This does make
inverting them less convenient but saves space as the forward index is less
useful then the inverted index during search.

__3. Generating Inverted Index:__
Inverted indexes are generated by multiple threads and hence we need to
have to first generated temporary indexes and then merge them. For a large
number of large files this approach is faster. It does require some extra space
but the temporary files are deleted as soon as they are merged into the main
index. So for a large number of threads, this is not an issue. We used 2
threads in the demo.
We have also chosen not to save the hit list with the inverted index as we can
get that information during the search ranking from the forward index in
constant time as well and save space.


## Unit Tests

*Proper unit tests have only been written for inverted index so far*

To test the functionality of different modules in the project first understand the
following files / scripts:

__run_test.py:__ is the file through which we can test the functionality of other
modules (lexicon, forward/inverted index). To test a specific functionality, we
will first make changes as required to its respective unit_test/* file and then
we will import and call the functions to be checked in the run.py. After that,
we can simply compile and run the run.py file.

__config.py:__ setup all the paths for different modules (already setup)

__unit_tests/test_lexicon:__ is setup for testing different functions defined in
lexicon.py file.

__unit_tests/test_forward_index:__ is setup for testing functionality of
forward_index.py.

__unit_tests/test_inverted_index:__ is setup for testing inverted_index.py
